{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ebcda",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 1️⃣ Imports\n",
    "# ===============================\n",
    "from typing import Dict, Any, Optional, ClassVar\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "import psycopg2\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ===============================\n",
    "# 2️⃣ Pydantic Model for LLM Output\n",
    "# ===============================\n",
    "class CodeFixResponse(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents a structured code fix from the LLM.\n",
    "    \"\"\"\n",
    "    issue_number: str\n",
    "    type_of_issue: str\n",
    "    from_line: int\n",
    "    to_line: int\n",
    "    original_code: str\n",
    "    fixed_code: str\n",
    "    justification: str\n",
    "    confidence: float = Field(..., ge=0.0, le=1.0)\n",
    "\n",
    "    # Optional: store example in schema\n",
    "    model_config: ClassVar[Dict[str, Any]] = {\n",
    "        \"json_schema_extra\": {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"issue_number\": \"S2111\",\n",
    "                    \"type_of_issue\": \"BUG\",\n",
    "                    \"from_line\": 42,\n",
    "                    \"to_line\": 45,\n",
    "                    \"original_code\": \"my_resource = open()\",\n",
    "                    \"fixed_code\": \"my_resource = open()\\nmy_resource.close()\",\n",
    "                    \"justification\": \"Prevents resource leaks\",\n",
    "                    \"confidence\": 0.92\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def to_embedding_text(self) -> str:\n",
    "        \"\"\"\n",
    "        Convert object to deterministic text for embedding.\n",
    "        \"\"\"\n",
    "        return f\"\"\"\n",
    "Issue: {self.issue_number}\n",
    "Type: {self.type_of_issue}\n",
    "Lines: {self.from_line}-{self.to_line}\n",
    "\n",
    "Original:\n",
    "{self.original_code}\n",
    "\n",
    "Fixed:\n",
    "{self.fixed_code}\n",
    "\n",
    "Justification:\n",
    "{self.justification}\n",
    "\"\"\".strip()\n",
    "\n",
    "# ===============================\n",
    "# 3️⃣ AgentState for LangGraph\n",
    "# ===============================\n",
    "class AgentState(BaseModel):\n",
    "    \"\"\"\n",
    "    State passed between LangGraph nodes.\n",
    "    \"\"\"\n",
    "    sonar_issue: Dict[str, Any]\n",
    "    llm_raw_output: Optional[str] = None\n",
    "    fix_response: Optional[CodeFixResponse] = None\n",
    "    error: Optional[str] = None\n",
    "    top_k: int = 5\n",
    "\n",
    "# ===============================\n",
    "# 4️⃣ LM Studio Client\n",
    "# ===============================\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:1234/v1\",  # LM Studio endpoint\n",
    "    api_key=\"lm-studio\",\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 5️⃣ LangGraph Nodes\n",
    "# ===============================\n",
    "\n",
    "# Node 1: Call LLM to generate fix\n",
    "def llm_fix_node(state: AgentState) -> AgentState:\n",
    "    issue = state.sonar_issue\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Return ONLY valid JSON matching this schema:\n",
    "{CodeFixResponse.model_json_schema()}\n",
    "\n",
    "Sonar Issue:\n",
    "Rule: {issue['rule']}\n",
    "Type: {issue['type']}\n",
    "From Line: {issue['textRange']['startLine']}\n",
    "To Line: {issue['textRange']['endLine']}\n",
    "Code:\n",
    "{issue['code']}\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"openai/gpt-oss-20b\",\n",
    "        temperature=0.2,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Return ONLY valid JSON.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    state.llm_raw_output = response.choices[0].message.content\n",
    "    return state\n",
    "\n",
    "# Node 2: Validate JSON using Pydantic\n",
    "def validate_node(state: AgentState) -> AgentState:\n",
    "    try:\n",
    "        state.fix_response = CodeFixResponse.model_validate_json(\n",
    "            state.llm_raw_output\n",
    "        )\n",
    "        state.error = None\n",
    "    except Exception as e:\n",
    "        state.error = str(e)\n",
    "    return state\n",
    "\n",
    "# Node 3: Repair invalid JSON\n",
    "def repair_node(state: AgentState) -> AgentState:\n",
    "    repair_prompt = f\"\"\"\n",
    "Your previous response was invalid.\n",
    "\n",
    "ERROR:\n",
    "{state.error}\n",
    "\n",
    "Return corrected JSON ONLY.\n",
    "Schema:\n",
    "{CodeFixResponse.model_json_schema()}\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"openai/gpt-oss-20b\",\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Return ONLY valid JSON.\"},\n",
    "            {\"role\": \"user\", \"content\": repair_prompt}\n",
    "        ]\n",
    "    )\n",
    "    state.llm_raw_output = response.choices[0].message.content\n",
    "    return state\n",
    "\n",
    "# Node 4: Store embedding + payload into pgvector\n",
    "def store_node(state: AgentState) -> AgentState:\n",
    "    fix = state.fix_response\n",
    "    if not fix:\n",
    "        logger.warning(\"No fix response to store.\")\n",
    "        return state  # safety\n",
    "\n",
    "    try:\n",
    "        # 1️⃣ Convert to text for embedding\n",
    "        embedding_text = fix.to_embedding_text()\n",
    "\n",
    "        # 2️⃣ Generate embedding\n",
    "        response = client.embeddings.create(\n",
    "            model=\"text-embedding-nomic-embed-text-v1.5:3\",\n",
    "            input=embedding_text\n",
    "        )\n",
    "        embedding = response.data[0].embedding  # list of floats\n",
    "\n",
    "        # 3️⃣ Store in PostgreSQL / pgvector\n",
    "        # Use the full DSN/connection URI (includes sslmode and channel_binding)\n",
    "        dsn = (\n",
    "            \"postgresql://neondb_owner:npg_CxYy4SoZ3Xtw@\"\n",
    "            \"ep-withered-math-ahmrxvtc-pooler.c-3.us-east-1.aws.neon.tech/\"\n",
    "            \"neondb?sslmode=require&channel_binding=require\"\n",
    "        )\n",
    "\n",
    "        conn = psycopg2.connect(dsn)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        # Convert embedding list to pgvector format (comma-separated string wrapped in brackets)\n",
    "        embedding_str = \"[\" + \",\".join(map(str, embedding)) + \"]\"\n",
    "\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO code_issues (issue_number, embedding, payload)\n",
    "            VALUES (%s, %s::vector, %s)\n",
    "            ON CONFLICT (issue_number) DO UPDATE\n",
    "            SET embedding = EXCLUDED.embedding,\n",
    "                payload = EXCLUDED.payload\n",
    "            \"\"\",\n",
    "            (\n",
    "                fix.issue_number,\n",
    "                embedding_str,\n",
    "                json.dumps(fix.model_dump())\n",
    "            )\n",
    "        )\n",
    "\n",
    "        conn.commit()\n",
    "        logger.info(f\"Successfully stored issue {fix.issue_number} in pgvector.\")\n",
    "\n",
    "    except psycopg2.Error as db_err:\n",
    "        logger.error(f\"Database error while storing: {db_err}\")\n",
    "        state.error = f\"Database error: {str(db_err)}\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error in store_node: {e}\")\n",
    "        state.error = f\"Store error: {str(e)}\"\n",
    "    finally:\n",
    "        # Ensure connection is closed\n",
    "        try:\n",
    "            if cur:\n",
    "                cur.close()\n",
    "            if conn:\n",
    "                conn.close()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return state\n",
    "\n",
    "# ===============================\n",
    "# 6️⃣ Conditional Router\n",
    "# ===============================\n",
    "def validation_router(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Decide whether to repair or store based on validation.\n",
    "    \"\"\"\n",
    "    return \"store\" if state.error is None else \"repair\"\n",
    "\n",
    "\n",
    "\n",
    "def search_similar_issues(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Search pgvector for top-K similar code issues based on embedding.\n",
    "\n",
    "    Args:\n",
    "        code_snippet: The new code snippet to search for.\n",
    "        top_k: 5\n",
    "\n",
    "    Returns:\n",
    "        List of CodeFixResponse objects (top similar past fixes).\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(\"Generating embedding for query code snippet\")\n",
    "\n",
    "    code_snippet = \"my_resource = open()\"\n",
    "\n",
    "    logger.info(f\"Generating embedding for query code snippet {code_snippet}\")\n",
    "    text_to_embed = code_snippet\n",
    "    embedding_response = client.embeddings.create(\n",
    "        model=\"text-embedding-nomic-embed-text-v1.5:3\",\n",
    "        input=text_to_embed\n",
    "    )\n",
    "    query_embedding = embedding_response.data[0].embedding\n",
    "    logger.info(f\"Successfully generated query embedding with {len(query_embedding)} dimensions\")\n",
    "\n",
    "    # 2️⃣ Connect to PostgreSQL / pgvector\n",
    "    logger.info(\"Connecting to PostgreSQL pgvector database\")\n",
    "    dsn = (\n",
    "        \"postgresql://<username>:<password>\"\n",
    "        \"ep-withered-math-ahmrxvtc-pooler.c-3.us-east-1.aws.neon.tech/\"\n",
    "        \"neondb?sslmode=require&channel_binding=require\"\n",
    "    )\n",
    "\n",
    "    conn = psycopg2.connect(dsn)\n",
    "    cur = conn.cursor()\n",
    "    logger.info(\"Successfully connected to database\")\n",
    "\n",
    "    # 3️⃣ Execute similarity search using state.top_k\n",
    "    logger.info(f\"Executing similarity search for top {state.top_k} issues\")\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        SELECT payload\n",
    "        FROM code_issues\n",
    "        ORDER BY embedding <#> %s::vector\n",
    "        LIMIT %s\n",
    "        \"\"\",\n",
    "        (query_embedding, state.top_k)\n",
    "    )\n",
    "\n",
    "    rows = cur.fetchall()\n",
    "    logger.info(f\"Retrieved {len(rows)} similar issues from database\")\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "    # 4️⃣ Convert payload JSON to Pydantic objects\n",
    "    similar_issues: List[CodeFixResponse] = []\n",
    "    for (payload_json,) in rows:\n",
    "        try:\n",
    "            issue = CodeFixResponse.model_validate(payload_json)\n",
    "            similar_issues.append(issue)\n",
    "            logger.info(f\"Found similar issue: {issue.issue_number}\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to parse payload: {e}\")\n",
    "            continue\n",
    "\n",
    "    state.similar_issues = similar_issues\n",
    "    logger.info(f\"Successfully returned {len(similar_issues)} similar issues\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 7️⃣ Build LangGraph\n",
    "# ===============================\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"llm_fix\", llm_fix_node)\n",
    "graph.add_node(\"validate\", validate_node)\n",
    "graph.add_node(\"repair\", repair_node)\n",
    "graph.add_node(\"store\", store_node)\n",
    "graph.add_node(\"search_similar_issues\", search_similar_issues)\n",
    "\n",
    "\n",
    "graph.set_entry_point(\"llm_fix\")\n",
    "graph.add_edge(\"llm_fix\", \"validate\")\n",
    "graph.add_conditional_edges(\n",
    "    \"validate\",\n",
    "    validation_router,\n",
    "    {\n",
    "        \"repair\": \"repair\",\n",
    "        \"store\": \"store\"\n",
    "    }\n",
    ")\n",
    "graph.add_edge(\"repair\", \"validate\")\n",
    "graph.add_edge(\"store\", \"search_similar_issues\")\n",
    "graph.add_edge(\"search_similar_issues\", END)\n",
    "\n",
    "agent = graph.compile()\n",
    "\n",
    "# ===============================\n",
    "# 8️⃣ Sample Sonar Issue JSON\n",
    "# ===============================\n",
    "sonar_issue_json = {\n",
    "    \"rule\": \"S2111\",\n",
    "    \"type\": \"BUG\",\n",
    "    \"textRange\": {\"startLine\": 42, \"endLine\": 45},\n",
    "    \"code\": \"my_resource = open()\\n# missing close\"\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# 9️⃣ Invoke the Agent\n",
    "# ===============================\n",
    "initial_state = {\"sonar_issue\": sonar_issue_json,     \"top_k\": 3  # specify top_k here\n",
    "}\n",
    "final_state = agent.invoke(initial_state)\n",
    "\n",
    "# ===============================\n",
    "# 10️⃣ Check Results\n",
    "# ===============================\n",
    "print(\"LLM Raw Output:\\n\", final_state)\n",
    "if final_state.get('llm_raw_output'):\n",
    "    print(\"Fixed Code:\\n\", final_state.get('llm_raw_output').get('fix_response').get('fixed_code'))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
